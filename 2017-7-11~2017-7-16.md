* [done] 跑论文作者的代码，发现作者的代码也没有达到论文中的结果，调了些参数也没用，发邮件请教作者（没收到回复）
* [done] 改了两处和作者代码不一样的地方（target只用一个词，output层用激活函数），再经过网格法，坐标下降法调参（涉及6种参数），竟然达到了论文中的效果
（测试集超了一个点，开发集差了一个点）
* [done] 对这次实验作了部分总结
https://github.com/chncwang/experience-after-experience/blob/master/unseen%20target%E7%AB%8B%E5%9C%BA%E6%A3%80%E6%B5%8B.md
* [done] 对比并记录了用不用词向量、词向量是否在训练时更新的实验结果
* [done] 修复了一个数据文件编码的问题后，效果大幅下降，当时没仔细查原因，又乱调了一堆参数
* [done] print读取到的instance，对比前后的版本，查明了这个文件编码问题只影响到了4条训练数据
* [done] 听了光耀的word2vec的分享
* [doing] 由于未知原因，实验效果又恢复了，在处理一些内存错误（boost的字符串分隔函数竟然有内存错误），目前猜测之前的效果下降和内存错误有关
* [doing] 用auto labelled的数据作训练集，超参数不变（论文中如此），做同样的实验，实验效果暂时很差，猜测和内存错误相关
